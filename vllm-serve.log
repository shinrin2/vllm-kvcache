(llm-storage) yingh@yingh-Super-Server:~/Desktop/kvcache/vllm-kvcache/lmcache-ssd-example$ bash vllm-serve.sh
INFO 05-19 17:37:00 [__init__.py:239] Automatically detected platform cuda.
INFO 05-19 17:37:03 [api_server.py:1043] vLLM API server version 0.8.5.post1
INFO 05-19 17:37:03 [api_server.py:1044] args: Namespace(subparser='serve', model_tag='meta-llama/Llama-3.1-8B-Instruct', config='', host=None, port=8000, uvicorn_log_level='info', disable_uvicorn_access_log=False, allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, chat_template_content_format='auto', response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, enable_ssl_refresh=False, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_request_id_headers=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='meta-llama/Llama-3.1-8B-Instruct', task='auto', tokenizer=None, hf_config_path=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, allowed_local_media_path=None, load_format='auto', download_dir=None, model_loader_extra_config={}, use_tqdm_on_load=True, config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', max_model_len=8000, guided_decoding_backend='auto', reasoning_parser=None, logits_processor_pattern=None, model_impl='auto', distributed_executor_backend=None, pipeline_parallel_size=1, tensor_parallel_size=1, data_parallel_size=1, enable_expert_parallel=False, max_parallel_loading_workers=None, ray_workers_use_nsight=False, disable_custom_all_reduce=False, block_size=None, gpu_memory_utilization=0.9, swap_space=4, kv_cache_dtype='auto', num_gpu_blocks_override=None, enable_prefix_caching=None, prefix_caching_hash_algo='builtin', cpu_offload_gb=30.0, calculate_kv_scales=False, disable_sliding_window=False, use_v2_block_manager=True, seed=None, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, hf_token=None, hf_overrides=None, enforce_eager=False, max_seq_len_to_capture=8192, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config={}, limit_mm_per_prompt={}, mm_processor_kwargs=None, disable_mm_preprocessor_cache=False, enable_lora=None, enable_lora_bias=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=None, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', speculative_config=None, ignore_patterns=[], served_model_name=None, qlora_adapter_name_or_path=None, show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, max_num_batched_tokens=None, max_num_seqs=None, max_num_partial_prefills=1, max_long_partial_prefills=1, long_prefill_token_threshold=0, num_lookahead_slots=0, scheduler_delay_factor=0.0, preemption_mode=None, num_scheduler_steps=1, multi_step_stream_outputs=True, scheduling_policy='fcfs', enable_chunked_prefill=None, disable_chunked_mm_input=False, scheduler_cls='vllm.core.scheduler.Scheduler', override_neuron_config=None, override_pooler_config=None, compilation_config=None, kv_transfer_config=KVTransferConfig(kv_connector='LMCacheConnectorV1', kv_buffer_device='cuda', kv_buffer_size=1000000000.0, kv_role='kv_both', kv_rank=None, kv_parallel_size=1, kv_ip='127.0.0.1', kv_port=14579, kv_connector_extra_config={}), worker_cls='auto', worker_extension_cls='', generation_config='auto', override_generation_config=None, enable_sleep_mode=False, additional_config=None, enable_reasoning=False, disable_cascade_attn=False, disable_log_requests=False, max_log_len=None, disable_fastapi_docs=False, enable_prompt_tokens_details=False, enable_server_load_tracking=False, dispatch_function=<function ServeSubcommand.cmd at 0x7889736440e0>)
INFO 05-19 17:37:08 [config.py:717] This model supports multiple tasks: {'generate', 'classify', 'reward', 'embed', 'score'}. Defaulting to 'generate'.
INFO 05-19 17:37:08 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 05-19 17:37:10 [__init__.py:239] Automatically detected platform cuda.
INFO 05-19 17:37:12 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=meta-llama/Llama-3.1-8B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 05-19 17:37:13 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x795feb1f8290>
INFO 05-19 17:37:13 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 05-19 17:37:13 [factory.py:64] Creating v1 connector with name: LMCacheConnectorV1
WARNING 05-19 17:37:13 [base.py:58] Initializing KVConnectorBase_V1. This API is experimental and subject to change in the future as we iterate the design.
[2025-05-19 17:37:13,499] LMCache INFO: Loading LMCache config file disk-offload.yaml (utils.py:32:lmcache.integration.vllm.utils)
[2025-05-19 17:37:13,500] LMCache INFO: Creating LMCacheEngine instance vllm-instance (cache_engine.py:444:lmcache.experimental.cache_engine)
[2025-05-19 17:37:17,419] LMCache INFO: Creating LMCacheEngine with config: LMCacheEngineConfig(chunk_size=256, local_cpu=False, max_local_cpu_size=5.0, local_disk='local/disk_test/local_disk/', max_local_disk_size=5.0, remote_url=None, remote_serde='naive', save_decode_cache=False, enable_blending=False, blend_recompute_ratio=0.15, blend_min_tokens=256, blend_special_str=' # # ', enable_p2p=False, lookup_url=None, distributed_url=None, error_handling=False, enable_controller=False, lmcache_instance_id='lmcache_default_instance', controller_url=None, lmcache_worker_url=None, enable_nixl=False, nixl_role=None, nixl_peer_host=None, nixl_peer_port=None, nixl_buffer_size=None, nixl_buffer_device=None, nixl_enable_gc=False) (cache_engine.py:73:lmcache.experimental.cache_engine)
[2025-05-19 17:37:17,419] LMCache INFO: Initializing usage context. (usage_context.py:235:lmcache.usage_context)
INFO 05-19 17:37:19 [cuda.py:221] Using Flash Attention backend on V1 engine.
WARNING 05-19 17:37:19 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
INFO 05-19 17:37:19 [gpu_model_runner.py:1329] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
INFO 05-19 17:37:36 [weight_utils.py:265] Using model weights format ['*.safetensors']
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:02<00:08,  2.87s/it]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:04<00:04,  2.32s/it]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:08<00:03,  3.13s/it]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:12<00:00,  3.41s/it]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:12<00:00,  3.18s/it]

INFO 05-19 17:37:49 [loader.py:458] Loading weights took 12.90 seconds
INFO 05-19 17:37:49 [gpu_model_runner.py:1347] Model loading took 1.9884 GiB and 29.989566 seconds
INFO 05-19 17:37:56 [backends.py:420] Using cache directory: /home/yingh/.cache/vllm/torch_compile_cache/8d6eaa9003/rank_0_0 for vLLM's torch.compile
INFO 05-19 17:37:56 [backends.py:430] Dynamo bytecode transform time: 7.27 s
[rank0]:W0519 17:37:57.833000 122735 site-packages/torch/_inductor/utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode
INFO 05-19 17:37:59 [backends.py:136] Cache the graph of shape None for later use
INFO 05-19 17:38:21 [backends.py:148] Compiling a graph for general shape takes 23.97 s
INFO 05-19 17:41:37 [monitor.py:33] torch.compile takes 31.24 s in total
INFO 05-19 17:41:43 [kv_cache_utils.py:634] GPU KV cache size: 36,208 tokens
INFO 05-19 17:41:43 [kv_cache_utils.py:637] Maximum concurrency for 8,000 tokens per request: 4.53x
INFO 05-19 18:16:42 [gpu_model_runner.py:1686] Graph capturing finished in 2099 secs, took 0.29 GiB
INFO 05-19 18:17:04 [core.py:159] init engine (profile, create kv cache, warmup model) took 2355.10 seconds
INFO 05-19 18:17:04 [factory.py:64] Creating v1 connector with name: LMCacheConnectorV1
WARNING 05-19 18:17:04 [base.py:58] Initializing KVConnectorBase_V1. This API is experimental and subject to change in the future as we iterate the design.
INFO 05-19 18:17:04 [core_client.py:439] Core engine process 0 ready.
WARNING 05-19 18:17:04 [config.py:1239] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
INFO 05-19 18:17:04 [serving_chat.py:118] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
INFO 05-19 18:17:04 [serving_completion.py:61] Using default completion sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
INFO 05-19 18:17:04 [api_server.py:1090] Starting vLLM API server on http://0.0.0.0:8000
INFO 05-19 18:17:04 [launcher.py:28] Available routes are:
INFO 05-19 18:17:04 [launcher.py:36] Route: /openapi.json, Methods: HEAD, GET
INFO 05-19 18:17:04 [launcher.py:36] Route: /docs, Methods: HEAD, GET
INFO 05-19 18:17:04 [launcher.py:36] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 05-19 18:17:04 [launcher.py:36] Route: /redoc, Methods: HEAD, GET
INFO 05-19 18:17:04 [launcher.py:36] Route: /health, Methods: GET
INFO 05-19 18:17:04 [launcher.py:36] Route: /load, Methods: GET
INFO 05-19 18:17:04 [launcher.py:36] Route: /ping, Methods: POST, GET
INFO 05-19 18:17:04 [launcher.py:36] Route: /tokenize, Methods: POST
INFO 05-19 18:17:04 [launcher.py:36] Route: /detokenize, Methods: POST
INFO 05-19 18:17:04 [launcher.py:36] Route: /v1/models, Methods: GET
INFO 05-19 18:17:04 [launcher.py:36] Route: /version, Methods: GET
INFO 05-19 18:17:04 [launcher.py:36] Route: /v1/chat/completions, Methods: POST
INFO 05-19 18:17:04 [launcher.py:36] Route: /v1/completions, Methods: POST
INFO 05-19 18:17:04 [launcher.py:36] Route: /v1/embeddings, Methods: POST
INFO 05-19 18:17:04 [launcher.py:36] Route: /pooling, Methods: POST
INFO 05-19 18:17:04 [launcher.py:36] Route: /score, Methods: POST
INFO 05-19 18:17:04 [launcher.py:36] Route: /v1/score, Methods: POST
INFO 05-19 18:17:04 [launcher.py:36] Route: /v1/audio/transcriptions, Methods: POST
INFO 05-19 18:17:04 [launcher.py:36] Route: /rerank, Methods: POST
INFO 05-19 18:17:04 [launcher.py:36] Route: /v1/rerank, Methods: POST
INFO 05-19 18:17:04 [launcher.py:36] Route: /v2/rerank, Methods: POST
INFO 05-19 18:17:04 [launcher.py:36] Route: /invocations, Methods: POST
INFO 05-19 18:17:04 [launcher.py:36] Route: /metrics, Methods: GET
INFO:     Started server process [122653]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     127.0.0.1:38184 - "GET /v1/models HTTP/1.1" 200 OK
INFO 05-19 19:34:34 [chat_utils.py:397] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.
ERROR 05-19 19:34:34 [serving_chat.py:200] Error in preprocessing prompt inputs
ERROR 05-19 19:34:34 [serving_chat.py:200] Traceback (most recent call last):
ERROR 05-19 19:34:34 [serving_chat.py:200]   File "/home/yingh/miniconda3/envs/llm-storage/lib/python3.11/site-packages/vllm/entrypoints/openai/serving_chat.py", line 183, in create_chat_completion
ERROR 05-19 19:34:34 [serving_chat.py:200]     ) = await self._preprocess_chat(
ERROR 05-19 19:34:34 [serving_chat.py:200]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-19 19:34:34 [serving_chat.py:200]   File "/home/yingh/miniconda3/envs/llm-storage/lib/python3.11/site-packages/vllm/entrypoints/openai/serving_engine.py", line 451, in _preprocess_chat
ERROR 05-19 19:34:34 [serving_chat.py:200]     prompt_inputs = await self._tokenize_prompt_input_async(
ERROR 05-19 19:34:34 [serving_chat.py:200]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-19 19:34:34 [serving_chat.py:200]   File "/home/yingh/miniconda3/envs/llm-storage/lib/python3.11/concurrent/futures/thread.py", line 58, in run
ERROR 05-19 19:34:34 [serving_chat.py:200]     result = self.fn(*self.args, **self.kwargs)
ERROR 05-19 19:34:34 [serving_chat.py:200]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-19 19:34:34 [serving_chat.py:200]   File "/home/yingh/miniconda3/envs/llm-storage/lib/python3.11/site-packages/vllm/entrypoints/openai/serving_engine.py", line 281, in _tokenize_prompt_input
ERROR 05-19 19:34:34 [serving_chat.py:200]     return next(
ERROR 05-19 19:34:34 [serving_chat.py:200]            ^^^^^
ERROR 05-19 19:34:34 [serving_chat.py:200]   File "/home/yingh/miniconda3/envs/llm-storage/lib/python3.11/site-packages/vllm/entrypoints/openai/serving_engine.py", line 304, in _tokenize_prompt_inputs
ERROR 05-19 19:34:34 [serving_chat.py:200]     yield self._normalize_prompt_text_to_input(
ERROR 05-19 19:34:34 [serving_chat.py:200]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-19 19:34:34 [serving_chat.py:200]   File "/home/yingh/miniconda3/envs/llm-storage/lib/python3.11/site-packages/vllm/entrypoints/openai/serving_engine.py", line 196, in _normalize_prompt_text_to_input
ERROR 05-19 19:34:34 [serving_chat.py:200]     return self._validate_input(request, input_ids, input_text)
ERROR 05-19 19:34:34 [serving_chat.py:200]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-19 19:34:34 [serving_chat.py:200]   File "/home/yingh/miniconda3/envs/llm-storage/lib/python3.11/site-packages/vllm/entrypoints/openai/serving_engine.py", line 253, in _validate_input
ERROR 05-19 19:34:34 [serving_chat.py:200]     raise ValueError(
ERROR 05-19 19:34:34 [serving_chat.py:200] ValueError: This model's maximum context length is 8000 tokens. However, you requested 15386 tokens in the messages, Please reduce the length of the messages.
INFO:     127.0.0.1:38184 - "POST /v1/chat/completions HTTP/1.1" 400 Bad Request
^BINFO:     127.0.0.1:54756 - "GET /v1/models HTTP/1.1" 200 OK
ERROR 05-19 19:37:34 [serving_chat.py:200] Error in preprocessing prompt inputs
ERROR 05-19 19:37:34 [serving_chat.py:200] Traceback (most recent call last):
ERROR 05-19 19:37:34 [serving_chat.py:200]   File "/home/yingh/miniconda3/envs/llm-storage/lib/python3.11/site-packages/vllm/entrypoints/openai/serving_chat.py", line 183, in create_chat_completion
ERROR 05-19 19:37:34 [serving_chat.py:200]     ) = await self._preprocess_chat(
ERROR 05-19 19:37:34 [serving_chat.py:200]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-19 19:37:34 [serving_chat.py:200]   File "/home/yingh/miniconda3/envs/llm-storage/lib/python3.11/site-packages/vllm/entrypoints/openai/serving_engine.py", line 451, in _preprocess_chat
ERROR 05-19 19:37:34 [serving_chat.py:200]     prompt_inputs = await self._tokenize_prompt_input_async(
ERROR 05-19 19:37:34 [serving_chat.py:200]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-19 19:37:34 [serving_chat.py:200]   File "/home/yingh/miniconda3/envs/llm-storage/lib/python3.11/concurrent/futures/thread.py", line 58, in run
ERROR 05-19 19:37:34 [serving_chat.py:200]     result = self.fn(*self.args, **self.kwargs)
ERROR 05-19 19:37:34 [serving_chat.py:200]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-19 19:37:34 [serving_chat.py:200]   File "/home/yingh/miniconda3/envs/llm-storage/lib/python3.11/site-packages/vllm/entrypoints/openai/serving_engine.py", line 281, in _tokenize_prompt_input
ERROR 05-19 19:37:34 [serving_chat.py:200]     return next(
ERROR 05-19 19:37:34 [serving_chat.py:200]            ^^^^^
ERROR 05-19 19:37:34 [serving_chat.py:200]   File "/home/yingh/miniconda3/envs/llm-storage/lib/python3.11/site-packages/vllm/entrypoints/openai/serving_engine.py", line 304, in _tokenize_prompt_inputs
ERROR 05-19 19:37:34 [serving_chat.py:200]     yield self._normalize_prompt_text_to_input(
ERROR 05-19 19:37:34 [serving_chat.py:200]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-19 19:37:34 [serving_chat.py:200]   File "/home/yingh/miniconda3/envs/llm-storage/lib/python3.11/site-packages/vllm/entrypoints/openai/serving_engine.py", line 196, in _normalize_prompt_text_to_input
ERROR 05-19 19:37:34 [serving_chat.py:200]     return self._validate_input(request, input_ids, input_text)
ERROR 05-19 19:37:34 [serving_chat.py:200]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-19 19:37:34 [serving_chat.py:200]   File "/home/yingh/miniconda3/envs/llm-storage/lib/python3.11/site-packages/vllm/entrypoints/openai/serving_engine.py", line 253, in _validate_input
ERROR 05-19 19:37:34 [serving_chat.py:200]     raise ValueError(
ERROR 05-19 19:37:34 [serving_chat.py:200] ValueError: This model's maximum context length is 8000 tokens. However, you requested 15386 tokens in the messages, Please reduce the length of the messages.
INFO:     127.0.0.1:54756 - "POST /v1/chat/completions HTTP/1.1" 400 Bad Request
INFO:     127.0.0.1:42392 - "GET /v1/models HTTP/1.1" 200 OK
INFO 05-19 19:37:57 [logger.py:39] Received request chatcmpl-67d0f29e085341f0846eafb0a087aa86: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nBASH(1)                                 General Commands Manual                                BASH(1)\n\nNAME\n       bash - GNU Bourne-Again SHell\n\nSYNOPSIS\n       bash [options] [command_string | file]\n\nCOPYRIGHT\n       Bash is Copyright (C) 1989-2020 by the Free Software Foundation, Inc.\n\nDESCRIPTION\n       Bash  is  an  sh-compatible  command  language interpreter that executes commands read from the\n       standard input or from a file.  Bash also incorporates useful features  from  the  Korn  and  C\n       shells (ksh and csh).\n\n       Bash  is  intended  to be a conformant implementation of the Shell and Utilities portion of the\n       IEEE POSIX specification (IEEE Standard 1003.1).  Bash can be configured to be POSIX-conformant\n       by default.\n\nOPTIONS\n       All of the single-character shell options documented in the description of the set builtin com‐\n       mand, including -o, can be used as options when the shell is invoked.  In addition, bash inter‐\n       prets the following options when it is invoked:\n\n       -c        If  the  -c option is present, then commands are read from the first non-option argu‐\n                 ment command_string.  If there are arguments after the command_string, the first  ar‐\n                 gument  is  assigned to $0 and any remaining arguments are assigned to the positional\n                 parameters.  The assignment to $0 sets the name of the shell, which is used in  warn‐\n                 ing and error messages.\n       -i        If the -i option is present, the shell is interactive.\n       -l        Make bash act as if it had been invoked as a login shell (see INVOCATION below).\n       -r        If  the  -r option is present, the shell becomes restricted (see RESTRICTED SHELL be‐\n                 low).\n       -s        If the -s option is present, or if no arguments remain after option processing,  then\n                 commands are read from the standard input.  This option allows the positional parame‐\n                 ters to be set when invoking an interactive shell or when  reading  input  through  a\n                 pipe.\n       -v        Print shell input lines as they are read.\n       -x        Print commands and their arguments as they are executed.\n       -D        A  list of all double-quoted strings preceded by $ is printed on the standard output.\n                 These are the strings that are subject to language translation when the  current  lo‐\n                 cale is not C or POSIX.  This implies the -n option; no commands will be executed.\n       [-+]O [shopt_option]\n                 shopt_option  is  one  of  the shell options accepted by the shopt builtin (see SHELL\n                 BUILTIN COMMANDS below).  If shopt_option is present, -O sets the value of  that  op‐\n                 tion;  +O  unsets  it.   If shopt_option is not supplied, the names and values of the\n                 shell options accepted by shopt are printed on the standard output.  If  the  invoca‐\n                 tion option is +O, the output is displayed in a format that may be reused as input.\n       --        A  --  signals  the end of options and disables further option processing.  Any argu‐\n                 ments after the -- are treated as filenames and  arguments.   An  argument  of  -  is\n                 equivalent to --.\n\n       Bash  also  interprets  a  number of multi-character options.  These options must appear on the\n       command line before the single-character options to be recognized.\n\n       --debugger\n              Arrange for the debugger profile to be executed before the shell starts.  Turns  on  ex‐\n              tended  debugging  mode (see the description of the extdebug option to the shopt builtin\n              below).\n       --dump-po-strings\n              Equivalent to -D, but the output is in the GNU gettext po (portable object) file format.\n       --dump-strings\n              Equivalent to -D.\n       --help Display a usage message on standard output and exit successfully.\n       --init-file file\n       --rcfile file\n              Execute  commands  from  file  instead  of   the   system   wide   initialization   file\n              /etc/bash.bashrc and the standard personal initialization file ~/.bashrc if the shell is\n              interactive (see INVOCATION below).\n\n       --login\n              Equivalent to -l.\n\n       --noediting\n              Do not use the GNU readline library to read command lines when the shell is interactive.\n\n       --noprofile\n              Do not read either the system-wide startup file /etc/profile or any of the personal ini‐\n              tialization files ~/.bash_profile, ~/.bash_login, or ~/.profile.  By default, bash reads\n              these files when it is invoked as a login shell (see INVOCATION below).\n\n       --norc Do not read and execute the system wide initialization  file  /etc/bash.bashrc  and  the\n              personal  initialization  file ~/.bashrc if the shell is interactive.  This option is on\n              by default if the shell is invoked as sh.\n\n       --posix\n              Change the behavior of bash where the default operation differs from the POSIX  standard\n              to  match  the  standard (posix mode).  See SEE ALSO below for a reference to a document\n              that details how posix mode affects bash\'s behavior.\n\n       --restricted\n              The shell becomes restricted (see RESTRICTED SHELL below).\n\n       --verbose\n              Equivalent to -v.\n\n       --version\n              Show version information for this instance of bash on the standard output and exit  suc‐\n              cessfully.\n\nARGUMENTS\n       If arguments remain after option processing, and neither the -c nor the -s option has been sup‐\n       plied, the first argument is assumed to be the name of a file containing  shell  commands.   If\n       bash  is invoked in this fashion, $0 is set to the name of the file, and the positional parame‐\n       ters are set to the remaining arguments.  Bash reads and executes commands from this file, then\n       exits.   Bash\'s  exit status is the exit status of the last command executed in the script.  If\n       no commands are executed, the exit status is 0.  An attempt is first made to open the  file  in\n       the  current  directory,  and,  if no file is found, then the shell searches the directories in\n       PATH for the script.\n\nINVOCATION\n       A login shell is one whose first character of argument zero is a -, or  one  started  with  the\n       --login option.\n\n       An  interactive  shell is one started without non-option arguments (unless -s is specified) and\n       without the -c option whose standard input and error are both connected to terminals (as deter‐\n       mined  by  isatty(3)), or one started with the -i option.  PS1 is set and $- includes i if bash\n       is interactive, allowing a shell script or a startup file to test this state.\n\n       The following paragraphs describe how bash executes its startup files.  If any of the files ex‐\n       ist  but  cannot be read, bash reports an error.  Tildes are expanded in filenames as described\n       below under Tilde Expansion in the EXPANSION section.\n\n       When bash is invoked as an interactive login shell, or as  a  non-interactive  shell  with  the\n       --login  option,  it first reads and executes commands from the file /etc/profile, if that file\n       exists.  After reading that file, it looks for ~/.bash_profile, ~/.bash_login, and  ~/.profile,\n       in  that order, and reads and executes commands from the first one that exists and is readable.\n       The --noprofile option may be used when the shell is started to inhibit this behavior.\n\n       When an interactive login shell exits, or a  non-interactive  login  shell  executes  the  exit\n       builtin command, bash reads and executes commands from the file ~/.bash_logout, if it exists.\n\n       When  an  interactive  shell that is not a login shell is started, bash reads and executes com‐\n       mands from /etc/bash.bashrc and ~/.bashrc, if these files exist.  This may be inhibited by  us‐\n       ing  the  --norc option.  The --rcfile file option will force bash to read and execute commands\n       from file instead of /etc/bash.bashrc and ~/.bashrc.\n\n       When bash is started non-interactively, to run a shell script, for example, it  looks  for  the\n       variable  BASH_ENV  in the environment, expands its value if it appears there, and uses the ex‐\n       panded value as the name of a file to read and execute.  Bash behaves as if the following  com‐\n       mand were executed:\n              if [ -n "$BASH_ENV" ]; then . "$BASH_ENV"; fi\n       but the value of the PATH variable is not used to search for the filename.\n\n       If  bash is invoked with the name sh, it tries to mimic the startup behavior of historical ver‐\n       sions of sh as closely as possible, while conforming to the POSIX standard as well.   When  in‐\n       voked  as  an  interactive  login shell, or a non-interactive shell with the --login option, it\n       first attempts to read and execute commands from /etc/profile and ~/.profile,  in  that  order.\n       The  --noprofile  option  may be used to inhibit this behavior.  When invoked as an interactive\n       shell with the name sh, bash looks for the variable ENV, expands its value if  it  is  defined,\n       and  uses  the expanded value as the name of a file to read and execute.  Since a shell invoked\n       as sh does not attempt to read and execute commands from any other startup files, the  --rcfile\n       option  has  no  effect.   A non-interactive shell invoked with the name sh does not attempt to\n       read any other startup files.  When invoked as sh, bash enters posix  mode  after  the  startup\n       files are read.\n\n       When  bash  is  started  in posix mode, as with the --posix command line option, it follows the\n       POSIX standard for startup files.  In this mode, interactive shells expand the ENV variable and\n       commands  are  read  and  executed  from  the  file whose name is the expanded value.  No other\n       startup files are read.\n\n       Bash attempts to determine when it is being run with its standard input connected to a  network\n       connection, as when executed by the remote shell daemon, usually rshd, or the secure shell dae‐\n       mon sshd.  If bash determines it is being run in this fashion, it reads and  executes  commands\n       from  ~/.bashrc  and  ~/.bashrc, if these files exist and are readable.  It will not do this if\n       invoked as sh.  The --norc option may be used to inhibit this behavior, and the --rcfile option\n       may  be  used  to force another file to be read, but neither rshd nor sshd generally invoke the\n       shell with those options or allow them to be specified.\n\n       If the shell is started with the effective user (group) id not equal to the real  user  (group)\n       id,  and  the -p option is not supplied, no startup files are read, shell functions are not in‐\n       herited from the environment, the SHELLOPTS, BASHOPTS, CDPATH,  and  GLOBIGNORE  variables,  if\n       they  appear in the environment, are ignored, and the effective user id is set to the real user\n       id.  If the -p option is supplied at invocation, the startup behavior is the same, but the  ef‐\n       fective user id is not reset.\n\nDEFINITIONS\n       The following definitions are used throughout the rest of this document.\n       blank  A space or tab.\n       word   A  sequence of characters considered as a single unit by the shell.  Also known as a to‐\n              ken.\n       name   A word consisting only of alphanumeric characters and underscores, and beginning with an\n              alphabetic character or an underscore.  Also referred to as an identifier.\n       metacharacter\n              A character that, when unquoted, separates words.  One of the following:\n              |  & ; ( ) < > space tab newline\n       control operator\n              A token that performs a control function.  It is one of the following symbols:\n              || & && ; ;; ;& ;;& ( ) | |& <newline>\n\nRESERVED WORDS\n       Reserved  words  are  words  that have a special meaning to the shell.  The following words are\n       recognized as reserved when unquoted and either the first word of a command (see SHELL  GRAMMAR\n       below),  the  third word of a case or select command (only in is valid), or the third word of a\n       for command (only in and do are valid):\n\n       ! case  coproc  do done elif else esac fi for function if in select then until while {  }  time\n       [[ ]]\n\nSHELL GRAMMAR\n   Simple Commands\n       A  simple  command  is  a sequence of optional variable assignments followed by blank-separated\n       words and redirections, and terminated by a control operator.  The  first  word  specifies  the\n       command  to be executed, and is passed as argument zero.  The remaining words are passed as ar‐\n       guments to the invoked command.\n\n       The return value of a simple command is its exit status, or 128+n if the command is  terminated\n       by signal n.\n\n   Pipelines\n       A pipeline is a sequence of one or more commands separated by one of the control operators | or\n       |&.  The format for a pipeline is:\n\n              [time [-p]] [ ! ] command [ [|⎪|&] command2 ... ]\n\n       The standard output of command is connected via a pipe to the standard input of command2.  This\n       connection  is  performed before any redirections specified by the command (see REDIRECTION be‐\n       low).  If |& is used, command\'s standard error, in addition to its  standard  output,  is  con‐\n       nected  to  command2\'s  standard  input through the pipe; it is shorthand for 2>&1 |.  This im‐\n       plicit redirection of the standard error to the standard output is performed after any redirec‐\n       tions specified by the command.\n\n       The return status of a pipeline is the exit status of the last command, unless the pipefail op‐\n       tion is enabled.  If pipefail is enabled, the pipeline\'s return status is the value of the last\n       (rightmost)  command to exit with a non-zero status, or zero if all commands exit successfully.\n       If the reserved word !  precedes a pipeline, the exit status of that pipeline  is  the  logical\n       negation  of the exit status as described above.  The shell waits for all commands in the pipe‐\n       line to terminate before returning a value.\n\n       If the time reserved word precedes a pipeline, the elapsed as well as user and system time con‐\n       sumed  by  its  execution are reported when the pipeline terminates.  The -p option changes the\n       output format to that specified by POSIX.  When the shell is in posix mode, it does not  recog‐\n       nize  time as a reserved word if the next token begins with a `-\'.  The TIMEFORMAT variable may\n       be set to a format string that specifies how the timing information should  be  displayed;  see\n       the description of TIMEFORMAT under Shell Variables below.\n\n       When  the  shell  is in posix mode, time may be followed by a newline.  In this case, the shell\n       displays the total user and system time consumed by the shell and its children.  The TIMEFORMAT\n       variable may be used to specify the format of the time information.\n\n       Each  command  in a pipeline is executed as a separate process (i.e., in a subshell).  See COM‐\n       MAND EXECUTION ENVIRONMENT for a description of a subshell environment.  If the lastpipe option\n       is  enabled using the shopt builtin (see the description of shopt below), the last element of a\n       pipeline may be run by the shell process.\n\n   Lists\n       A list is a sequence of one or more pipelines separated by one of the operators ;,  &,  &&,  or\n       ||, and optionally terminated by one of ;, &, or <newline>.\n\n       Of these list operators, && and || have equal precedence, followed by ; and &, which have equal\n       precedence.\n\n       A sequence of one or more newlines may appear in a list instead of a semicolon to delimit  com‐\n       mands.\n\n       If  a  command  is  terminated by the control operator &, the shell executes the command in the\n       background in a subshell.  The shell does not wait for the command to finish,  and  the  return\n       status  is  0.   These are referred to as asynchronous commands.  Commands separated by a ; are\n       executed sequentially; the shell waits for each command to terminate in turn.  The return  sta‐\n       tus is the exit status of the last command executed.\n\n       AND  and OR lists are sequences of one or more pipelines separated by the && and || control op‐\n       erators, respectively.  AND and OR lists are executed with left associativity.  An AND list has\n       the form\n\n              command1 && command2\n\n       command2 is executed if, and only if, command1 returns an exit status of zero (success).\n\n       An OR list has the form\n\n              command1 || command2\n\n       command2 is executed if, and only if, command1 returns a non-zero exit status.  The return sta‐\n       tus of AND and OR lists is the exit status of the last command executed in the list.\n\n   Compound Commands\n       A compound command is one of the following.  In most cases a list in  a  command\'s  description\n       may be separated from the rest of the command by one or more newlines, and may be followed by a\n       newline in place of a semicolon.\n\n       (list) list is executed in a subshell environment (see COMMAND  EXECUTION  ENVIRONMENT  below).\n              Variable assignments and builtin commands that affect the shell\'s environment do not re‐\n              main in effect after the command completes.  The return status is  the  exit  status  of\n              list.\n\n       { list; }\n              list  is simply executed in the current shell environment.  list must be terminated with\n              a newline or semicolon.  This is known as a group command.  The  return  status  is  the\n              exit  status of list.  Note that unlike the metacharacters ( and ), { and } are reserved\n              words and must occur where a reserved word is permitted to be recognized.  Since they do\n              not  cause a word break, they must be separated from list by whitespace or another shell\n              metacharacter.\n\n       ((expression))\n              The expression is evaluated according to the  rules  described  below  under  ARITHMETIC\n              EVALUATION.   If the value of the expression is non-zero, the return status is 0; other‐\n              wise the return status is 1.  This is exactly equivalent to let "expression".\n\n       [[ expression ]]\n              Return a status of 0 or 1 depending on the evaluation of the conditional expression  ex‐\n              pression.   Expressions  are composed of the primaries described below under CONDITIONAL\n              EXPRESSIONS.  Word splitting and pathname expansion are not performed on the  words  be‐\n              tween  the  [[ and ]]; tilde expansion, parameter and variable expansion, arithmetic ex‐\n              pansion, command substitution, process substitution, and quote  removal  are  performed.\n              Conditional operators such as -f must be unquoted to be recognized as primaries.\n\n              When  used  with  [[, the < and > operators sort lexicographically using the current lo‐\n              cale.\n\n       See the description of the test builtin command (section SHELL BUILTIN COMMANDS below) for  the\n       handling of parameters (i.e.  missing parameters).\n\n       When  the == and != operators are used, the string to the right of the operator is considered a\n       pattern and matched according to the rules described below under Pattern Matching,  as  if  the\n       extglob  shell  option  were  enabled.  The = operator is equivalent to ==.  If the nocasematch\n       shell option is enabled, the match is performed without regard to the case of alphabetic  char‐\n       acters.   The  return value is 0 if the string matches (==) or does not match (!=) the pattern,\n       and 1 otherwise.  Any part of the pattern may be quoted to  force  the  quoted  portion  to  be\n       matched as a string.\n\n       An  additional  binary operator, =~, is available, with the same precedence as == and !=.  When\n       it is used, the string to the right of the operator is considered a POSIX extended regular  ex‐\n       pression  and  matched  accordingly (using the POSIX regcomp and regexec interfaces usually de‐\n       scribed in regex(3)).  The return value is 0 if the string matches the pattern,  and  1  other‐\n       wise.   If  the regular expression is syntactically incorrect, the conditional expression\'s re‐\n       turn value is 2.  If the nocasematch shell option is enabled, the match  is  performed  without\n       regard  to  the  case of alphabetic characters.  Any part of the pattern may be quoted to force\n       the quoted portion to be matched as a string.  Bracket expressions in regular expressions  must\n       be treated carefully, since normal quoting characters lose their meanings between brackets.  If\n       the pattern is stored in a shell variable, quoting the variable  expansion  forces  the  entire\n       pattern to be matched as a string.\n\n       The  pattern  will  match if it matches any part of the string.  Anchor the pattern using the ^\n       and $ regular expression operators to force it to match the entire string.  The array  variable\n       BASH_REMATCH  records  which  parts of the string matched the pattern.  The element of BASH_RE‐\n       MATCH with index 0 contains the portion of the string matching the entire  regular  expression.\n       Substrings  matched  by parenthesized subexpressions within the regular expression are saved in\n       the remaining BASH_REMATCH indices. The element of BASH_REMATCH with index n is the portion  of\n       the string matching the nth parenthesized subexpression.\n\n       Expressions may be combined using the following operators, listed in decreasing order of prece‐\n       dence:\n\n              ( expression )\n                     Returns the value of expression.  This may be used to override the normal  prece‐\n                     dence of operators.\n              ! expression\n                     True if expression is false.\n              expression1 && expression2\n                     True if both expression1 and expression2 are true.\n              expression1 || expression2\n                     True if either expression1 or expression2 is true.\n\n              The  && and || operators do not evaluate expression2 if the value of expression1 is suf‐\n              ficient to determine the return value of the entire conditional expression.\n\n       for name [ [ in [ word ... ] ] ; ] do list ; done\n              The list of words following in is expanded, generating a list of  items.   The  variable\n              name  is  set  to each element of this list in turn, and list is executed each time.  If\n              the in word is omitted, the for command executes list once for each positional parameter\n              that  is  set  (see PARAMETERS below).  The return status is the exit status of the last\n              command that executes.  If the expansion of the items following in results in  an  empty\n              list, no commands are executed, and the return status is 0.\n\n       for (( expr1 ; expr2 ; expr3 )) ; do list ; done\n              First, the arithmetic expression expr1 is evaluated according to the rules described be‐\n              low under ARITHMETIC EVALUATION.  The arithmetic expression expr2 is then evaluated  re‐\n              peatedly  until  it  evaluates  to zero.  Each time expr2 evaluates to a non-zero value,\n              list is executed and the arithmetic expression expr3 is evaluated.  If any expression is\n              omitted, it behaves as if it evaluates to 1.  The return value is the exit status of the\n              last command in list that is executed, or false if any of the expressions is invalid.\n\n       select name [ in word ] ; do list ; done\n              The list of words following in is expanded, generating a list of items.  The set of  ex‐\n              panded  words  is  printed  on the standard error, each preceded by a number.  If the in\n              word is omitted, the positional parameters are printed (see PARAMETERS below).  The  PS3\n              prompt  is then displayed and a line read from the standard input.  If the line consists\n              of a number corresponding to one of the displayed words, then the value of name  is  set\n              to  that  word.  If the line is empty, the words and prompt are displayed again.  If EOF\n              is read, the command completes.  Any other value read causes name to  be  set  to  null.\n              The line read is saved in the variable REPLY.  The list is executed after each selection\n              until a break command is executed.  The exit status of select is the exit status of  the\n              last command executed in list, or zero if no commands were executed.\n\n       case word in [ [(] pattern [ | pattern ] ... ) list ;; ] ... esac\n              A  case  command first expands word, and tries to match it against each pattern in turn,\n              using the matching rules described under Pattern Matching below.  The word  is  expanded\n              using  tilde  expansion, parameter and variable expansion, arithmetic expansion, command\n              substitution, process substitution and quote removal.  Each pattern examined is expanded\n              using  tilde  expansion, parameter and variable expansion, arithmetic expansion, command\n              substitution, and process substitution.  If the nocasematch shell option is enabled, the\n              match is performed without regard to the case of alphabetic characters.  When a match is\n              found, the corresponding list is executed.  If the ;; operator is  used,  no  subsequent\n              matches are attempted after the first pattern match.  Using ;& in place of ;; causes ex‐\n              ecution to continue with the list associated with the next set of patterns.   Using  ;;&\n              in  place of ;; causes the shell to test the next pattern list in the statement, if any,\n              and execute any associated list on a successful match, continuing the case statement ex‐\n              ecution  as  if the pattern list had not matched.  The exit status is zero if no pattern\n              matches.  Otherwise, it is the exit status of the last command executed in list.\n\n       if list; then list; [ elif list; then list; ] ... [ else list; ] fi\n              The if list is executed.  If its exit status is zero, the then list is executed.  Other‐\n              wise,  each  elif  list  is executed in turn, and if its exit status is zero, the corre‐\n              sponding then list is executed and the command completes.  Otherwise, the else  list  is\n              executed,  if present.  The exit status is the exit status of the last command executed,\n              or zero if no condition tested true.\n\n       while list-1; do list-2; done\n       until list-1; do list-2; done\n              The while command continuously executes the list list-2 as long as the last  command  in\n              the  list  list-1 returns an exit status of zero.  The until command is identical to the\n              while command, except that the test is negated: list-2 is executed as long as  the  last\n              command  in list-1 returns a non-zero exit status.  The exit status of the while and un‐\n              til commands is the exit status of the last command executed in list-2, or zero if  none\n              was executed.\n\n   Coprocesses\n       A  coprocess  is a shell command preceded by the coproc reserved word.  A coprocess is executed\n       asynchronously in a subshell, as if the command had been terminated with the &  control  opera‐\n       tor, with a two-way pipe established between the executing shell and the coprocess.\n\n       The format for a coprocess is:\n\n              coproc [NAME] command [redirections]\n\n       This  creates  a  coprocess  named  NAME.  If NAME is not supplied, the default name is COPROC.\n       NAME must not be supplied if command is a simple command (see above); otherwise, it  is  inter‐\n       preted as the first word of the simple command.  When the coprocess is executed, the shell cre‐\n       ates an array variable (see Arrays below) named NAME in the context  of  the  executing  shell.\n       The  standard  output  of command is connected via a pipe to a file descriptor in the executing\n       shell, and that file descriptor is assigned to NAME[0].  The standard input of command is  con‐\n       nected  via a pipe to a file descriptor in the executing shell, and that file descriptor is as‐\n       signed to NAME[1].  This pipe is established before any redirections specified by  the  command\n       (see  REDIRECTION  below).  The file descriptors can be utilized as arguments to shell commands\n       and redirections using standard word expansions.  Other than those created to  execute  command\n       and process substitutions, the file descriptors are not available in subshells.  The process ID\n       of the shell spawned to execute the coprocess  is  available  as  the  value  of  the  variable\n       NAME_PID.  The wait builtin command may be used to wait for the coprocess to terminate.\n\n       Since  the  coprocess  is created as an asynchronous command, the coproc command always returns\n       success.  The return status of a coprocess is the exit status of command.\n\n   Shell Function Definitions\n       A shell function is an object that is called like a simple command and executes a compound com‐\n       mand with a new set of positional parameters.  Shell functions are declared as follows:\n\n       fname () compound-command [redirection]\n       function fname [()] compound-command [redirection]\n              This  defines  a  function named fname.  The reserved word function is optional.  If the\n              function reserved word is supplied, the parentheses are optional.  The body of the func‐\n              tion  is the compound command compound-command (see Compound Commands above).  That com‐\n              mand is usually a list of commands between { and }, but may be any command listed  under\n              Compound  Commands above, with one exception: If the function reserved word is used, but\n              the parentheses are not supplied, the braces are required.  compound-command is executed\n              whenever  fname is specified as the name of a simple command.  When in posix mode, fname\n              must be a valid shell name and may not be the name of one of the POSIX special builtins.\n              In default mode, a function name can be any unquoted shell word that does not contain $.\n              Any redirections (see REDIRECTION below) specified when a function is defined  are  per‐\n              formed  when the function is executed.  The exit status of a function definition is zero\n              unless a syntax error occurs or a readonly function with the same name  already  exists.\n              When executed, the exit status of a function is the exit status of the last command exe‐\n              cuted in the body.  (See FUNCTIONS below.)\n\nCOMMENTS\n       In a non-interactive shell, or an interactive shell in which the interactive_comments option to\n       the shopt builtin is enabled (see SHELL BUILTIN COMMANDS below), a word beginning with # causes\n       that word and all remaining characters on that line to be ignored.  An interactive shell  with‐\n       out  the interactive_comments option enabled does not allow comments.  The interactive_comments\n       option is on by default in interactive shells.\n\nQUOTING\n       Quoting is used to remove the special meaning of certain characters  or  words  to  the  shell.\n       Quoting  can  be  used to disable special treatment for special characters, to prevent reserved\n       words from being recognized as such, and to prevent parameter expansion.\n\n       Each of the metacharacters listed above under DEFINITIONS has special meaning to the shell  and\n       must be quoted if it is to represent itself.\n\n       When the command history expansion facilities are being used (see HISTORY EXPANSION below), the\n       history expansion character, usually !, must be quoted to prevent history expansion.\n\n       There are three quoting mechanisms: the escape character, single quotes, and double quotes.\n\n       A non-quoted backslash (\\) is the escape character.  It preserves the literal value of the next\n       character that follows, with the exception of <newline>.  If a \\<newline> pair appears, and the\n       backslash is not itself quoted, the \\<newline> is treated as a line continuation (that  is,  it\n       is removed from the input stream and effectively ignored).\n\n       Enclosing  characters in single quotes preserves the literal value of each character within the\n       quotes.  A single quote may not occur between single quotes, even when preceded by a backslash.\n\n       Enclosing characters in double quotes preserves the literal value of all characters within  the\n       quotes,  with  the  exception  of $, `, \\, and, when history expansion is enabled, !.  When the\n       shell is in posix mode, the ! has no special meaning within double quotes,  even  when  history\n       expansion  is  enabled.   The  characters  $  and  ` retain their special meaning within double\n       quotes.  The backslash retains its special meaning only when followed by one of  the  following\n       characters:  $,  `,  ",  \\, or <newline>.  A double quote may be quoted within double quotes by\n       preceding it with a backslash.  If enabled, history expansion will be  performed  unless  an  !\n       appearing in double quotes is escaped using a backslash.  The backslash preceding the !  is not\n       removed.\n\n       The special parameters * and @ have special meaning when in double quotes (see  PARAMETERS  be‐\n       low).\n\n       Words of the form $\'string\' are treated specially.  The word expands to string, with backslash-\n       escaped characters replaced as specified by the ANSI C standard.  Backslash  escape  sequences,\n       if present, are decoded as follows:\n              \\a     alert (bell)\n              \\b     backspace\n              \\e\n              \\E     an escape character\n              \\f     form feed\n              \\n     new line\n              \\r     carriage return\n              \\t     horizontal tab\n              \\v     vertical tab\n              \\\\     backslash\n              \\\'     single quote\n              \\"     double quote\n              \\?     question mark\n              \\nnn   the  eigh\n\nSummarize bash in 2 sentences.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.9, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=153, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:42392 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 05-19 19:37:57 [async_llm.py:252] Added request chatcmpl-67d0f29e085341f0846eafb0a087aa86.
[2025-05-19 19:37:57,932] LMCache INFO: Reqid: chatcmpl-67d0f29e085341f0846eafb0a087aa86, Total tokens 7847, LMCache hit tokens: 0, need to load: 0 (vllm_v1_adapter.py:543:lmcache.integration.vllm.vllm_v1_adapter)
[2025-05-19 19:41:07,432] LMCache INFO: Storing KV cache for 2048 out of 2048 tokens for request chatcmpl-67d0f29e085341f0846eafb0a087aa86 (vllm_v1_adapter.py:497:lmcache.integration.vllm.vllm_v1_adapter)
[2025-05-19 19:44:17,123] LMCache INFO: Storing KV cache for 2048 out of 4096 tokens for request chatcmpl-67d0f29e085341f0846eafb0a087aa86 (vllm_v1_adapter.py:497:lmcache.integration.vllm.vllm_v1_adapter)
[2025-05-19 19:47:26,800] LMCache INFO: Storing KV cache for 2048 out of 6144 tokens for request chatcmpl-67d0f29e085341f0846eafb0a087aa86 (vllm_v1_adapter.py:497:lmcache.integration.vllm.vllm_v1_adapter)
INFO 05-19 19:47:57 [async_llm.py:411] Aborted request chatcmpl-67d0f29e085341f0846eafb0a087aa86.
INFO 05-19 19:47:57 [async_llm.py:318] Request chatcmpl-67d0f29e085341f0846eafb0a087aa86 aborted.
[2025-05-19 19:50:12,874] LMCache INFO: Storing KV cache for 1703 out of 7847 tokens for request chatcmpl-67d0f29e085341f0846eafb0a087aa86 (vllm_v1_adapter.py:497:lmcache.integration.vllm.vllm_v1_adapter)
INFO:     127.0.0.1:52876 - "GET /v1/models HTTP/1.1" 200 OK
INFO 05-19 20:03:00 [logger.py:39] Received request chatcmpl-fbb3b350787c4d0a9d3fb6d13b8dac06: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nBASH(1)                                 General Commands Manual                                BASH(1)\n\nNAME\n       bash - GNU Bourne-Again SHell\n\nSYNOPSIS\n       bash [options] [command_string | file]\n\nCOPYRIGHT\n       Bash is Copyright (C) 1989-2020 by the Free Software Foundation, Inc.\n\nDESCRIPTION\n       Bash  is  an  sh-compatible  command  language interpreter that executes commands read from the\n       standard input or from a file.  Bash also incorporates useful features  from  the  Korn  and  C\n       shells (ksh and csh).\n\n       Bash  is  intended  to be a conformant implementation of the Shell and Utilities portion of the\n       IEEE POSIX specification (IEEE Standard 1003.1).  Bash can be configured to be POSIX-conformant\n       by default.\n\nOPTIONS\n       All of the single-character shell options documented in the description of the set builtin com‐\n       mand, including -o, can be used as options when the shell is invoked.  In addition, bash inter‐\n       prets the foll\n\nSummarize bash in 2 sentences.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.9, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=7728, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:52876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 05-19 20:03:00 [async_llm.py:252] Added request chatcmpl-fbb3b350787c4d0a9d3fb6d13b8dac06.
[2025-05-19 20:03:00,998] LMCache INFO: Reqid: chatcmpl-fbb3b350787c4d0a9d3fb6d13b8dac06, Total tokens 272, LMCache hit tokens: 256, need to load: 0 (vllm_v1_adapter.py:543:lmcache.integration.vllm.vllm_v1_adapter)
[2025-05-19 20:03:10,466] LMCache INFO: Storing KV cache for 16 out of 272 tokens for request chatcmpl-fbb3b350787c4d0a9d3fb6d13b8dac06 (vllm_v1_adapter.py:497:lmcache.integration.vllm.vllm_v1_adapter)
INFO 05-19 20:03:15 [loggers.py:111] Engine 000: Avg prompt throughput: 27.2 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:03:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:03:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:03:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:03:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:04:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:04:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:04:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:04:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:04:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:04:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:05:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:05:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:05:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:05:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:05:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:05:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:06:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:06:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:06:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:06:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:06:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:06:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:07:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.2%
INFO 05-19 20:07:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:07:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:07:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:07:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:07:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:08:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:08:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:08:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:08:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:08:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:08:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:09:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:09:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:09:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:09:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:09:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:09:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:10:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:10:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:10:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:10:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:10:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:10:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:11:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:11:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:11:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:11:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:11:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:11:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:12:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:12:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:12:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:12:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:12:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:12:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:13:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:13:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:13:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:13:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:13:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:13:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:14:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:14:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:14:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:14:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 3.2%
INFO 05-19 20:14:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 3.2%
INFO 05-19 20:14:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 3.2%
INFO 05-19 20:15:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 3.2%
INFO 05-19 20:15:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 3.2%
INFO 05-19 20:15:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 3.2%
INFO 05-19 20:15:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 3.2%
INFO 05-19 20:15:45 [logger.py:39] Received request chatcmpl-87fadaff5ac14bd7a4da5f847fc2d094: prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nBASH(1)                                 General Commands Manual                                BASH(1)\n\nNAME\n       bash - GNU Bourne-Again SHell\n\nSYNOPSIS\n       bash [options] [command_string | file]\n\nCOPYRIGHT\n       Bash is Copyright (C) 1989-2020 by the Free Software Foundation, Inc.\n\nDESCRIPTION\n       Bash  is  an  sh-compatible  command  language interpreter that executes commands read from the\n       standard input or from a file.  Bash also incorporates useful features  from  the  Korn  and  C\n       shells (ksh and csh).\n\n       Bash  is  intended  to be a conformant implementation of the Shell and Utilities portion of the\n       IEEE POSIX specification (IEEE Standard 1003.1).  Bash can be configured to be POSIX-conformant\n       by default.\n\nOPTIONS\n       All of the single-character shell options documented in the description of the set builtin com‐\n       mand, including -o, can be used as options when the shell is invoked.  In addition, bash inter‐\n       prets the foll\n\nSummarize bash in 2 sentences.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.9, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=7728, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:52876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 05-19 20:15:45 [async_llm.py:252] Added request chatcmpl-87fadaff5ac14bd7a4da5f847fc2d094.
[2025-05-19 20:15:45,319] LMCache INFO: Reqid: chatcmpl-87fadaff5ac14bd7a4da5f847fc2d094, Total tokens 272, LMCache hit tokens: 271, need to load: 15 (vllm_v1_adapter.py:543:lmcache.integration.vllm.vllm_v1_adapter)
INFO 05-19 20:15:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 3.2%
INFO 05-19 20:15:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 3.2%
INFO 05-19 20:16:05 [loggers.py:111] Engine 000: Avg prompt throughput: 27.2 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:16:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:16:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:16:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:16:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:16:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:17:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:17:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:17:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:17:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:17:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:17:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:18:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:18:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:18:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:18:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:18:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:18:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:19:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:19:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:19:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:19:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:19:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:19:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 6.1%
INFO 05-19 20:20:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:20:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:20:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:20:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:20:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:20:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:21:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:21:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:21:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:21:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:21:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:21:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:22:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:22:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:22:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:22:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:22:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:22:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:23:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:23:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:23:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:23:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:23:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:23:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:24:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:24:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:24:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:24:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:24:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:24:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:25:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:25:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:25:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:25:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:25:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:25:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:26:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:26:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:26:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:26:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:26:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:26:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:27:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:27:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 6.1%
INFO 05-19 20:27:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 6.1%
INFO 05-19 20:27:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 6.1%
INFO 05-19 20:27:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 6.1%
INFO 05-19 20:27:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 6.1%
INFO 05-19 20:28:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 6.1%
INFO 05-19 20:28:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 6.1%
INFO 05-19 20:28:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 6.1%
INFO 05-19 20:28:35 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 6.1%
INFO 05-19 20:28:45 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 6.1%
INFO 05-19 20:28:55 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 6.1%
INFO 05-19 20:29:05 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 6.1%
INFO 05-19 20:29:15 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 6.1%
INFO 05-19 20:29:25 [loggers.py:111] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 6.1%